# 设置开发集与测试集
### 开发集和测试集应该服从同一分布
只要定义好了开发集和测试集，那么就应该专注于提升开发集的性能表现，开发集和测试集的不匹配会引发额外的不确定性
### 开发集和测试集应该有多大
开发集应该尽可能的大，至少应该区分出不同算法之间的性能差异

例如算法A的准确性为90.1%，算法B的准确性为90.0%，那么样本容量为100的开发集，无法检测出0.1%的性能差异

总体数据量比较一般时，可以将测试集的数据量定义为开发集的30%
### 使用单值评估指标进行优化
单值评估指标（single-number evaluation matric），望文生义，就是指一个数字就能评估模型性能好坏的指标。如果有多个指标来衡量的话，想办法把他们合成一个指标，例如取这些指标的算术平均数或者是F1分数
### 优化指标与满意度指标
这是另外一种组合多个指标的评估方法，那就是对指标进行分类，在满足“满意度指标”的前提下，尽可能的提高“优化指标”

以算法准确率和运行时间为例，将这两个指标怎么组合也感觉不太合理，可以将运行时间设计为“满意度指标”，算法准确率为“优化指标”，即：在一个可以接受的模型运行时间内，例如100ms，尽可能低将分类器的准确率最大化

如果有很多个指标来衡量一个模型，那么只设置一个“优化指标”，尽可能的去提高这一个指标，将其余指标保持在一定范围内即可
### 通过开发集和度量指标来加速迭代
通常的建立一个机器学习系统的过程：

1.有一个idea

2.编写code来实现你的idea

3.根据实验（experiment）结果来判断idea是否行得通，在这一基础上学习总结，形成新的idea

然后1-3不停的循环

所以，迭代的越快，那么进展的也就越快

有开发集、测试集和度量指标的重要性就得以体现：在开发集上评估性能就可以帮助你判断当前的方向是否正确

### 何时修改开发集、测试集和指标
 1.实际数据的分布和开发集、测试集数据的分布情况不同

 2.算法在开发集上过拟合了

 3.该指标不是项目应该优化的目标
 例如，你的指标评估认为分类器A优于分类器B。但是，你实际发现分类器A竟然允许出现一些色情图片。
 此时说明，目前所优化的指标并不能辨别出哪种算法在实际体验中更优秀，说明该指标并不可靠。

 有两种办法：
 
 1.修改指标，对出现色情图片的情况执行严重的惩罚

 2.强烈建议选择一个新的指标，而不是在一个不可信的指标上浪费太多时间
# 基础误差分析
### 误差分析：根据开发集样本来评估你的idea
误差分析（Error Analysis）指的是检查被算法误分类的过程，以便找到造成这些误差的原因

例如，如果你的分类器将狗的图片错误分类成了猫
1. 收集 100 个开发集中被误分类的样本，即造成系统误差的样本。
2. 人为查看这些样本，并计算其中狗的比例。
查看误分类样本的这一过程称为误差分析。在上面的例子中，如果只有 5% 误分类的图像是
狗，那么无论你在狗的问题上做多少的算法改进，最终都不会消除超过原有的 5% 误差 . 也即
是说 5% 是该计划项目所能起到帮助的“上限”（最大可能值）。所以如果整个系统当前的精度
为 90%（对应误差为 10%），那么这种改进最多能将精度提升到 90.5% （对应误差下降到
9.5% ， 改进了原有 10% 误差其中的 5%）。
相反，如果你发现 50% 的误分类图像是狗，那就可以自信地说这个项目将效果明显，它可以
将精度从 90% 提升到 95% （相对误差减少 50%，整体误差由 10% 下降到 5%）

### 清晰错误标注的开发集和测试集样本
在项目初始阶段容许一些误标注的开发集/测试集样本并不罕见，你可以选择在系统改进到一
定程度时再来考虑被误标注的样本，因为这些误差在整体误差中的占比会逐渐增大

不论你使用什么方式修正开发集标签，请记住，要将同样的方式应用于你的测试集，这可以保
持二者服从相同的分布
### 将大型开发集拆分为两个子集，专注其一
将开发集明确地分为 Eyeball 和 Blackbox 开发两个子集将很有帮助，它使你了解在人为的误
差分析过程中 Eyeball 开发集何时开始发生过拟合
### Eyeball 和 Blackbox 开发集该设置多大？
假设你的分类器有 5% 的错误率。为了确保在 Eyeball 开发集中有约 100 个误分类的样本，
样本开发集应该有约 2000 个样本（因为 0.05 * 2000 = 100）。分类器的错误率越低，为了获
得足够多的错误样本进行误差分析，需要的 Eyeball 开发集就越大
# 偏差与方差
### 偏差和方差：误差的两大来源
粗略地说，偏差指的是算法在大型训练集上的错误率；方差指的是算法在测试集上的表现低于训练集的程度

用均方误差（MSE）作为误差度量指标时，你可以写下偏差和方差对应的两个公式，并且证明总误差=偏差+方差

将训练集上的错误率，非正式的称为偏差（bias）
将算法在开发集上的表现比训练集上差多少，肥城市的将它称为方差（varlance）
### 偏差和方差举例
假设你的算法表现如下：

● 训练错误率 = 1%

● 开发错误率 = 11%

这其中存在什么问题呢？根据前一章的定义，我们估计偏差为 1%，方差为 10%（=11%-1%）。因此，它有一个很高的方差（high variance）。虽然分类器的训练误差非常低，但是并
没有成功泛化到开发集上。这也被叫做过拟合（overfitting）。
接下来，考虑如下情况：

● 训练错误率 = 15%

● 开发错误率 = 16%

我们估计偏差为 15%，方差为 1%。该分类器的错误率为 15%，没有很好地拟合训练集，但
它在开发集上的误差不比在训练集上的误差高多少。因此，该分类器具有较高的偏差（high
bias），而方差较低。我们称该算法是欠拟合（underfitting）的。
### 与最优错误率比较
偏差 = 最佳误差率（“不可避免偏差”）+ 可避免的偏差

理论上来说 所有的方差都是可避免的

在统计学上，最优错误率也被称为​贝叶斯错误率（Bayes error rate），或贝叶斯率
### 处理偏差和方差
下面是处理偏差和方差问题最简单的形式：

● 如果具有较高的可避免偏差，那么加大模型的规模（例如通过添加层/神经元数量来增加神经网络的大小）。

● 如果具有较高的方差，那么增加训练集的数据量。
